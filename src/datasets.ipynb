{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T22:08:26.931674Z",
     "start_time": "2024-08-26T22:08:26.383732Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "ds = load_dataset(\"enelpol/rag-mini-bioasq\", \"text-corpus\")\n",
    "# write the passage column to a json with id and passage\n",
    "# DatasetDict({\n",
    "#     test: Dataset({\n",
    "#         features: ['passage', 'id'],\n",
    "#         num_rows: 40181\n",
    "#     })\n",
    "# })\n",
    "json_data = {\n",
    "    \"total\": 0,\n",
    "    \"data\": []\n",
    "}\n",
    "for row in ds[\"test\"]:\n",
    "    json_data[\"data\"].append({\n",
    "        \"id\": row[\"id\"],\n",
    "        \"text\": row[\"passage\"]\n",
    "    })\n",
    "    json_data[\"total\"] += 1\n",
    "with open(\"../data/rag-mini-bioasq.json\", \"w\") as f:\n",
    "    f.write(json.dumps(json_data))\n",
    "    "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'id', 'relevant_passage_ids'],\n",
       "        num_rows: 4012\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'id', 'relevant_passage_ids'],\n",
       "        num_rows: 707\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:23:17.738974Z",
     "start_time": "2024-08-26T22:23:16.867705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"neural-bridge/rag-dataset-12000\")\n",
    "# DatasetDict({\n",
    "#     train: Dataset({\n",
    "#         features: ['context', 'question', 'answer'],\n",
    "#         num_rows: 9600\n",
    "#     })\n",
    "#     test: Dataset({\n",
    "#         features: ['context', 'question', 'answer'],\n",
    "#         num_rows: 2400\n",
    "#     })\n",
    "# })\n",
    "# combine the train and test set\n",
    "train = ds[\"train\"]\n",
    "valid = ds[\"test\"]\n",
    "\n",
    "# write the context column to a json with id and passage\n",
    "json_data = {\n",
    "    \"total\": 0,\n",
    "    \"data\": []\n",
    "}\n",
    "for row in train:\n",
    "    json_data[\"data\"].append({\n",
    "        \"id\": json_data[\"total\"],\n",
    "        \"text\": row[\"context\"]\n",
    "    })\n",
    "    json_data[\"total\"] += 1\n",
    "for row in valid:\n",
    "    json_data[\"data\"].append({\n",
    "        \"id\": json_data[\"total\"],\n",
    "        \"text\": row[\"context\"]\n",
    "    })\n",
    "    json_data[\"total\"] += 1\n",
    "with open(\"../data/rag-dataset-12000.json\", \"w\") as f:\n",
    "    f.write(json.dumps(json_data))\n",
    "    \n"
   ],
   "id": "4c37a7bfa229caf8",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:34:22.409027Z",
     "start_time": "2024-08-26T22:33:43.005487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "configs= ['ar', 'bn', 'de', 'en', 'es', 'fa', 'fi', 'fr', 'hi', 'id', 'ja', 'ko', 'ru', 'sw', 'te', 'th', 'yo', 'zh']\n",
    "# write the prompt column to a json with id and passage\n",
    "json_data = {\n",
    "    \"total\": 0,\n",
    "    \"data\": []\n",
    "}\n",
    "for config in configs:\n",
    "    ds = load_dataset(\"nthakur/mirage-eval-rag-output\", config)\n",
    "    # dev: Dataset({\n",
    "#         features: ['query_id', 'prompt', 'positive_ids', 'negative_ids', 'outputs', 'language_detection', 'en_detection', 'other_detection', 'Meta-Llama-3-8B-Instruct-fluency', 'Mistral-7B-Instruct-v0.3-fluency', 'citation_MAP@10', 'citation_Recall@10', 'answer_bleu', 'answer_rougeL', 'xlni_context_entailment', 'xlni_context_neutral', 'xlni_context_contradiction', 'bge-reranker-v2-m3-score', 'Meta-Llama-3-8B-Instruct-answer-eval', 'Mistral-7B-Instruct-v0.3-answer-eval'],\n",
    "#         num_rows: 787\n",
    "#     })\n",
    "# })\n",
    "\n",
    "    for row in ds[\"dev\"]:\n",
    "        json_data[\"data\"].append({\n",
    "            \"id\": row[\"query_id\"],\n",
    "            \"text\": row[\"prompt\"]\n",
    "        })\n",
    "        json_data[\"total\"] += 1\n",
    "\n",
    "with open(f\"../data/mirage-eval-rag-output.json\", \"w\") as f:\n",
    "    f.write(json.dumps(json_data))\n",
    "\n"
   ],
   "id": "132c15adbc92599e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.17M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6874ff80385f4baca71a68f2fc16a1b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/617 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1cbb407eaa04589ba64a0db5702b73a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.69M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5398fb0f48bc40aa981371e8d589ec4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/632 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0649952d22bd47238943117bb686e6c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.2M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd87d916342b43ffa160da6ef9eed3ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/1183 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7ccf80650464a01901b20aedaf60b64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.05M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "919fbe53ec544a33b9ed06cf6b918a01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/343 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c320866ea244885a4b4cc5c6417b0ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.70M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb8fdbfeda2e465f85534a27f28a7fe0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2303d2306b314435a9721897cf435733"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.33M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec359deee65d4541b7edcd2f041dafd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/939 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cd0e44575394fd892058e134cf4a8e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.51M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f98ae2bd04024cff9d586f7c00794523"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/797 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53f55effd6944dc1ad293dd2c56a90dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.54M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c086cccc45d478dab28aeeb03174f90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/213 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "535948c044eb4e0f95807fd3d10fefaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/17.0M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3923897aa7dc41b4978f5e0a50ca52ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/1247 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64fffbba90184925a84333d591904a1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.21M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "779834b70056487cb525a5f50aff98f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/481 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb63be984bca498089e61df1284ef47f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.28M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b7c962352644976952c02cedbcbfb9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81efc79cd52144a791a45549327951a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.48M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c305341948b4488ad5ba3e1bdd8aa2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/730 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1aa50e9e5c04e26a7cd7ccebbd9eaa1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2452a36abd447a88c660501b56dbf12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f0f7176eb884170bf467db8b34302a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.80M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55408cddca334412b1383589f74f2051"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating dev split:   0%|          | 0/391 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33af6024b1214c8d827eb65cf33209ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:36:38.187275Z",
     "start_time": "2024-08-26T22:36:37.708045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"rag-datasets/rag-mini-wikipedia\", \"text-corpus\")\n",
    "# DatasetDict({\n",
    "#     passages: Dataset({\n",
    "#         features: ['passage', 'id'],\n",
    "#         num_rows: 3200\n",
    "#     })\n",
    "# })\n",
    "# write the passage column to a json with id and passage\n",
    "json_data = {\n",
    "    \"total\": 0,\n",
    "    \"data\": []\n",
    "}\n",
    "for row in ds[\"passages\"]:\n",
    "    json_data[\"data\"].append({\n",
    "        \"id\": row[\"id\"],\n",
    "        \"text\": row[\"passage\"]\n",
    "    })\n",
    "    json_data[\"total\"] += 1\n",
    "with open(\"../data/rag-mini-wikipedia.json\", \"w\") as f:\n",
    "    f.write(json.dumps(json_data))"
   ],
   "id": "33f5be51446bf4eb",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:47:24.952849Z",
     "start_time": "2024-08-26T22:47:24.466483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"projecte-aina/RAG_Multilingual\")\n",
    "ds"
   ],
   "id": "124a689dedfeba03",
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": " (Request ID: Root=1-66cd05fc-50918c5548e63f8b5f6ae68a;3335d0bd-9e51-46a9-adca-8d50a62ab246)\n\n403 Forbidden: Please enable access to public gated repositories in your fine-grained token settings to view this repository..\nCannot access content at: https://huggingface.co/api/datasets/projecte-aina/RAG_Multilingual/paths-info/a7020cfffaeff43c23f2847da0b45df51a49faf3.\nIf you are trying to create or update content, make sure you have a token with the `write` role.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHfHubHTTPError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Login using e.g. `huggingface-cli login` to access this dataset\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprojecte-aina/RAG_Multilingual\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m ds\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/datasets/load.py:2606\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001B[0m\n\u001B[1;32m   2601\u001B[0m verification_mode \u001B[38;5;241m=\u001B[39m VerificationMode(\n\u001B[1;32m   2602\u001B[0m     (verification_mode \u001B[38;5;129;01mor\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mBASIC_CHECKS) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m save_infos \u001B[38;5;28;01melse\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mALL_CHECKS\n\u001B[1;32m   2603\u001B[0m )\n\u001B[1;32m   2605\u001B[0m \u001B[38;5;66;03m# Create a dataset builder\u001B[39;00m\n\u001B[0;32m-> 2606\u001B[0m builder_instance \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset_builder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2607\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2608\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2609\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2610\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2611\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2612\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2613\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2614\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2615\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2616\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2617\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2618\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2619\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_default_config_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2620\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2621\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2623\u001B[0m \u001B[38;5;66;03m# Return iterable dataset in case of streaming\u001B[39;00m\n\u001B[1;32m   2624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m streaming:\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/datasets/load.py:2277\u001B[0m, in \u001B[0;36mload_dataset_builder\u001B[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001B[0m\n\u001B[1;32m   2275\u001B[0m     download_config \u001B[38;5;241m=\u001B[39m download_config\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m download_config \u001B[38;5;28;01melse\u001B[39;00m DownloadConfig()\n\u001B[1;32m   2276\u001B[0m     download_config\u001B[38;5;241m.\u001B[39mstorage_options\u001B[38;5;241m.\u001B[39mupdate(storage_options)\n\u001B[0;32m-> 2277\u001B[0m dataset_module \u001B[38;5;241m=\u001B[39m \u001B[43mdataset_module_factory\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2278\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2279\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2280\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2281\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2282\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2283\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2285\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2286\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_default_config_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_require_default_config_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2287\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_require_custom_configs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2288\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2289\u001B[0m \u001B[38;5;66;03m# Get dataset builder class from the processing script\u001B[39;00m\n\u001B[1;32m   2290\u001B[0m builder_kwargs \u001B[38;5;241m=\u001B[39m dataset_module\u001B[38;5;241m.\u001B[39mbuilder_kwargs\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/datasets/load.py:1923\u001B[0m, in \u001B[0;36mdataset_module_factory\u001B[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001B[0m\n\u001B[1;32m   1918\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e1, \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m):\n\u001B[1;32m   1919\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[1;32m   1920\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a dataset script at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrelative_to_absolute_path(combined_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or any data file in the same directory. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1921\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m on the Hugging Face Hub either: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(e1)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me1\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1922\u001B[0m                 ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1923\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e1 \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1925\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[1;32m   1926\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a dataset script at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrelative_to_absolute_path(combined_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or any data file in the same directory.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1927\u001B[0m     )\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/datasets/load.py:1905\u001B[0m, in \u001B[0;36mdataset_module_factory\u001B[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001B[0m\n\u001B[1;32m   1889\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m HubDatasetModuleFactoryWithScript(\n\u001B[1;32m   1890\u001B[0m             path,\n\u001B[1;32m   1891\u001B[0m             revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1895\u001B[0m             trust_remote_code\u001B[38;5;241m=\u001B[39mtrust_remote_code,\n\u001B[1;32m   1896\u001B[0m         )\u001B[38;5;241m.\u001B[39mget_module()\n\u001B[1;32m   1897\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1898\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mHubDatasetModuleFactoryWithoutScript\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1899\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1900\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1901\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1902\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1903\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1904\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m-> 1905\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1906\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e1:\n\u001B[1;32m   1907\u001B[0m     \u001B[38;5;66;03m# All the attempts failed, before raising the error we should check if the module is already cached\u001B[39;00m\n\u001B[1;32m   1908\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/datasets/load.py:1221\u001B[0m, in \u001B[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1219\u001B[0m     download_config\u001B[38;5;241m.\u001B[39mdownload_desc \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading readme\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1220\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1221\u001B[0m     dataset_readme_path \u001B[38;5;241m=\u001B[39m \u001B[43mcached_path\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhf_dataset_url\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREPOCARD_FILENAME\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1225\u001B[0m     dataset_card_data \u001B[38;5;241m=\u001B[39m DatasetCard\u001B[38;5;241m.\u001B[39mload(Path(dataset_readme_path))\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/datasets/utils/file_utils.py:211\u001B[0m, in \u001B[0;36mcached_path\u001B[0;34m(url_or_filename, download_config, **download_kwargs)\u001B[0m\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    206\u001B[0m         storage_options\n\u001B[1;32m    207\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m storage_options\u001B[38;5;241m.\u001B[39mkeys() \u001B[38;5;241m<\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    208\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (download_config\u001B[38;5;241m.\u001B[39mstorage_options \u001B[38;5;129;01mand\u001B[39;00m download_config\u001B[38;5;241m.\u001B[39mstorage_options\u001B[38;5;241m.\u001B[39mkeys() \u001B[38;5;241m<\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[1;32m    209\u001B[0m     ):\n\u001B[1;32m    210\u001B[0m         storage_options \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 211\u001B[0m     output_path \u001B[38;5;241m=\u001B[39m \u001B[43mget_from_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl_or_filename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    216\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_etag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_etag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_url_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_url_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdownload_desc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_desc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisable_tqdm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdisable_tqdm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(url_or_filename):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# File, and it exists.\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     output_path \u001B[38;5;241m=\u001B[39m url_or_filename\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/datasets/utils/file_utils.py:583\u001B[0m, in \u001B[0;36mget_from_cache\u001B[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc, disable_tqdm)\u001B[0m\n\u001B[1;32m    581\u001B[0m     connected \u001B[38;5;241m=\u001B[39m ftp_head(url)\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m scheme \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps\u001B[39m\u001B[38;5;124m\"\u001B[39m} \u001B[38;5;129;01mor\u001B[39;00m storage_options\u001B[38;5;241m.\u001B[39mget(scheme):\n\u001B[0;32m--> 583\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mfsspec_head\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;66;03m# s3fs uses \"ETag\", gcsfs uses \"etag\"\u001B[39;00m\n\u001B[1;32m    585\u001B[0m     etag \u001B[38;5;241m=\u001B[39m (response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mETag\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124metag\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)) \u001B[38;5;28;01mif\u001B[39;00m use_etag \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/datasets/utils/file_utils.py:361\u001B[0m, in \u001B[0;36mfsspec_head\u001B[0;34m(url, storage_options)\u001B[0m\n\u001B[1;32m    359\u001B[0m _raise_if_offline_mode_is_enabled(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTried to reach \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    360\u001B[0m fs, path \u001B[38;5;241m=\u001B[39m url_to_fs(url, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(storage_options \u001B[38;5;129;01mor\u001B[39;00m {}))\n\u001B[0;32m--> 361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:540\u001B[0m, in \u001B[0;36mHfFileSystem.info\u001B[0;34m(self, path, refresh, revision, **kwargs)\u001B[0m\n\u001B[1;32m    538\u001B[0m     out \u001B[38;5;241m=\u001B[39m out1[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    539\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m refresh \u001B[38;5;129;01mor\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (expand_info \u001B[38;5;129;01mand\u001B[39;00m out \u001B[38;5;129;01mand\u001B[39;00m out[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_commit\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 540\u001B[0m     paths_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_api\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_paths_info\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresolved_path\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresolved_path\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath_in_repo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexpand\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpand_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresolved_path\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresolved_path\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    547\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m paths_info:\n\u001B[1;32m    548\u001B[0m         _raise_file_not_found(path, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/huggingface_hub/hf_api.py:3143\u001B[0m, in \u001B[0;36mHfApi.get_paths_info\u001B[0;34m(self, repo_id, paths, expand, revision, repo_type, token)\u001B[0m\n\u001B[1;32m   3133\u001B[0m headers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_hf_headers(token\u001B[38;5;241m=\u001B[39mtoken)\n\u001B[1;32m   3135\u001B[0m response \u001B[38;5;241m=\u001B[39m get_session()\u001B[38;5;241m.\u001B[39mpost(\n\u001B[1;32m   3136\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/api/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/paths-info/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3137\u001B[0m     data\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3141\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[1;32m   3142\u001B[0m )\n\u001B[0;32m-> 3143\u001B[0m \u001B[43mhf_raise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3144\u001B[0m paths_info \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mjson()\n\u001B[1;32m   3145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m   3146\u001B[0m     RepoFile(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpath_info) \u001B[38;5;28;01mif\u001B[39;00m path_info[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m RepoFolder(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpath_info)\n\u001B[1;32m   3147\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m path_info \u001B[38;5;129;01min\u001B[39;00m paths_info\n\u001B[1;32m   3148\u001B[0m ]\n",
      "File \u001B[0;32m~/research/DeepDiveVec/venv/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:367\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m403\u001B[39m:\n\u001B[1;32m    361\u001B[0m     message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    362\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Forbidden: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_message\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    363\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mCannot access content at: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    364\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf you are trying to create or update content, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    365\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmake sure you have a token with the `write` role.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    366\u001B[0m     )\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HfHubHTTPError(message, response\u001B[38;5;241m=\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    369\u001B[0m \u001B[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001B[39;00m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;66;03m# as well (request id and/or server error message)\u001B[39;00m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m HfHubHTTPError(\u001B[38;5;28mstr\u001B[39m(e), response\u001B[38;5;241m=\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mHfHubHTTPError\u001B[0m:  (Request ID: Root=1-66cd05fc-50918c5548e63f8b5f6ae68a;3335d0bd-9e51-46a9-adca-8d50a62ab246)\n\n403 Forbidden: Please enable access to public gated repositories in your fine-grained token settings to view this repository..\nCannot access content at: https://huggingface.co/api/datasets/projecte-aina/RAG_Multilingual/paths-info/a7020cfffaeff43c23f2847da0b45df51a49faf3.\nIf you are trying to create or update content, make sure you have a token with the `write` role."
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T22:42:47.808597Z",
     "start_time": "2024-08-26T22:42:47.411099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"llmware/rag_instruct_benchmark_tester\")\n",
    "\n",
    "# DatasetDict({\n",
    "#     train: Dataset({\n",
    "#         features: ['query', 'answer', 'context', 'sample_number', 'tokens', 'category'],\n",
    "#         num_rows: 200\n",
    "#     })\n",
    "# })\n",
    "# write the context column to a json with id and passage\n",
    "json_data = {\n",
    "    \"total\": 0,\n",
    "    \"data\": []\n",
    "}\n",
    "for row in ds[\"train\"]:\n",
    "    json_data[\"data\"].append({\n",
    "        \"id\": json_data[\"total\"],\n",
    "        \"text\": row[\"context\"]\n",
    "    })\n",
    "    json_data[\"total\"] += 1\n",
    "with open(\"../data/rag_instruct_benchmark_tester.json\", \"w\") as f:\n",
    "    f.write(json.dumps(json_data))"
   ],
   "id": "23dd85e4ed37c2d8",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T20:57:49.259217Z",
     "start_time": "2024-08-27T20:55:09.759246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# !git clone https://huggingface.co/datasets/MongoDB/subset_arxiv_papers_with_embeddings\n",
    "# load the dataset from json\n",
    "import json\n",
    "with open(\"../data/subset_arxiv_papers_with_embeddings.json\", \"r\") as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "# create np.array from json\n",
    "embeddings = []\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    embeddings.append(result[\"embedding\"])\n",
    "\n",
    "arr = np.array(embeddings)\n",
    "# save the np.array to a file\n",
    "np.save(\"../embeddings/subset_arxiv_papers_with_embeddings.npy\", arr)\n",
    "arr.shape"
   ],
   "id": "4df0151c7229e253",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T20:20:00.822115Z",
     "start_time": "2024-08-27T19:49:23.424437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Cohere/wikipedia-2023-11-embed-multilingual-v3\", \"zh\")\n",
    "# DatasetDict({\n",
    "#     train: Dataset({\n",
    "#         features: ['_id', 'url', 'title', 'text', 'emb'],\n",
    "#         num_rows: 10821\n",
    "#     })\n",
    "# })\n",
    "# write the emb column to np array and save it\n",
    "\n",
    "embeddings = []\n",
    "print(len(ds[\"train\"]))\n",
    "cnt = 0\n",
    "for row in ds[\"train\"]:\n",
    "    if cnt % 100000 == 0:\n",
    "        print(cnt)\n",
    "    cnt += 1\n",
    "    embeddings.append(row[\"emb\"])\n",
    "arr = np.array(embeddings)\n",
    "np.save(\"../embeddings/wikipedia-2023-11-embed-multilingual-v3_embedding.npy\", arr)\n",
    "arr.shape\n"
   ],
   "id": "56ab5121da4c94c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3fc389df2c842518f6dc108663d2a79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/26 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c6f47f00ba142dfa69d7ae6c0f96648"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2775260\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2775260, 1024)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T21:18:10.334253Z",
     "start_time": "2024-08-27T21:18:06.272810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"MongoDB/airbnb_embeddings\")\n",
    "\n",
    "# DatasetDict({\n",
    "#     train: Dataset({\n",
    "#         features: ['_id', 'listing_url', 'name', 'summary', 'space', 'description', 'neighborhood_overview', 'notes', 'transit', 'access', 'interaction', 'house_rules', 'property_type', 'room_type', 'bed_type', 'minimum_nights', 'maximum_nights', 'cancellation_policy', 'last_scraped', 'calendar_last_scraped', 'first_review', 'last_review', 'accommodates', 'bedrooms', 'beds', 'number_of_reviews', 'bathrooms', 'amenities', 'price', 'security_deposit', 'cleaning_fee', 'extra_people', 'guests_included', 'images', 'host', 'address', 'availability', 'review_scores', 'reviews', 'weekly_price', 'monthly_price', 'text_embeddings', 'image_embeddings'],\n",
    "#         num_rows: 5555\n",
    "#     })\n",
    "# })\n",
    "\n",
    "# Save text embeddings and image embeddings to np array and save them into two files\n",
    "text_embeddings = []\n",
    "image_embeddings = []\n",
    "for row in ds[\"train\"]:\n",
    "    # not none for each\n",
    "    if row[\"text_embeddings\"] is not None: \n",
    "        text_embeddings.append(row[\"text_embeddings\"])\n",
    "    if row[\"image_embeddings\"] is not None:\n",
    "        image_embeddings.append(row[\"image_embeddings\"])\n",
    "\n",
    "text_arr = np.array(text_embeddings)\n",
    "image_arr = np.array(image_embeddings)\n",
    "np.save(\"../embeddings/airbnb_text_embeddings.npy\", text_arr)\n",
    "np.save(\"../embeddings/airbnb_image_embeddings.npy\", image_arr)\n",
    "text_arr.shape, image_arr.shape\n"
   ],
   "id": "4696c79259db497d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5555, 1536), (4631, 512))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:14:57.286841Z",
     "start_time": "2024-08-29T01:56:08.937418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"asahi417/seamless-align-enA-frA.speaker-embedding.hubert-xl\", \"subset_1\")\n",
    "\n",
    "# DatasetDict({\n",
    "#     train: Dataset({\n",
    "#         features: ['line_no', 'enA.id', 'enA.laser_score', 'frA.id', 'frA.laser_score', 'frA.audio.speaker_embedding', 'frA.audio.speaker_embedding.full', 'enA.audio.speaker_embedding', 'enA.audio.speaker_embedding.full'],\n",
    "#         num_rows: 2343\n",
    "#     })\n",
    "# })\n",
    "\n",
    "# save the embeddings to np array and save them separately\n",
    "frA_audio_embeddings = []\n",
    "enA_audio_embeddings = []\n",
    "frA_audio_embeddings_full = []\n",
    "enA_audio_embeddings_full = []\n",
    "cnt = 0\n",
    "# for row in ds[\"train\"]:\n",
    "#     if row[\"frA.audio.speaker_embedding\"] is not None:\n",
    "#         frA_audio_embeddings.append(row[\"frA.audio.speaker_embedding\"])\n",
    "# arr_frA = np.array(frA_audio_embeddings)\n",
    "# np.save(\"../embeddings/seamless-align-enA-frA_frA_audio_embeddings.npy\", arr_frA)\n",
    "# print(arr_frA.shape)\n",
    "# \n",
    "# for row in ds[\"train\"]:\n",
    "#     if row[\"enA.audio.speaker_embedding\"] is not None:\n",
    "#         enA_audio_embeddings.append(row[\"enA.audio.speaker_embedding\"])\n",
    "# arr_enA = np.array(enA_audio_embeddings)\n",
    "# np.save(\"../embeddings/seamless-align-enA-frA_enA_audio_embeddings.npy\", arr_enA)\n",
    "# print(arr_enA.shape)\n",
    "\n",
    "# for row in ds[\"train\"]:\n",
    "#     if row[\"frA.audio.speaker_embedding.full\"] is not None:\n",
    "#         frA_audio_embeddings_full.append(row[\"frA.audio.speaker_embedding.full\"])\n",
    "# arr_frA_full = np.array(frA_audio_embeddings_full, dtype=object)\n",
    "# np.save(\"../embeddings/seamless-align-enA-frA_frA_audio_full_embeddings.npy\", arr_frA_full)\n",
    "\n",
    "for row in ds[\"train\"]:\n",
    "    if row[\"enA.audio.speaker_embedding.full\"] is not None:\n",
    "        enA_audio_embeddings_full.append(row[\"enA.audio.speaker_embedding.full\"])\n",
    "arr_enA_full = np.array(enA_audio_embeddings_full, dtype=object)\n",
    "np.save(\"../embeddings/seamless-align-enA-frA_enA_audio_full_embeddings.npy\", arr_enA_full)\n",
    "\n",
    "arr_enA_full.shape"
   ],
   "id": "ae0242c16e1146ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9e86f37965b4e4faeeb2c3d64efe559"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f93013981b247fa8c1e1da50cb7cb48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abbee7641af44935b67f2d8753e617df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2343,)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T02:27:18.849112Z",
     "start_time": "2024-08-29T02:27:18.770384Z"
    }
   },
   "cell_type": "code",
   "source": "arr_enA_full.shape",
   "id": "67a31628fac7e8b4",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr_enA_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43marr_enA_full\u001B[49m\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[0;31mNameError\u001B[0m: name 'arr_enA_full' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T22:25:44.896153Z",
     "start_time": "2024-08-27T22:25:41.765254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"asahi417/seamless-align-enA-esA.speaker-embedding.metavoice\", \"subset_1\")\n",
    "\n",
    "# DatasetDict({\n",
    "#     train: Dataset({\n",
    "#         features: ['line_no', 'enA.id', 'enA.laser_score', 'esA.id', 'esA.laser_score', 'esA.audio.speaker_embedding', 'enA.audio.speaker_embedding'],\n",
    "#         num_rows: 2178\n",
    "#     })\n",
    "# })\n",
    "\n",
    "# save the embeddings to np array and save them separately\n",
    "esA_audio_embeddings = []\n",
    "enA_audio_embeddings = []\n",
    "cnt = 0\n",
    "for row in ds[\"train\"]:\n",
    "    if row[\"esA.audio.speaker_embedding\"] is not None:\n",
    "        esA_audio_embeddings.append(row[\"esA.audio.speaker_embedding\"])\n",
    "arr_esA = np.array(esA_audio_embeddings)\n",
    "np.save(\"../embeddings/seamless-align-enA-esA_esA_audio_metavoice_embeddings.npy\", arr_esA)\n",
    "print(arr_esA.shape)\n",
    "\n",
    "for row in ds[\"train\"]:\n",
    "    if row[\"enA.audio.speaker_embedding\"] is not None:\n",
    "        enA_audio_embeddings.append(row[\"enA.audio.speaker_embedding\"])\n",
    "arr_enA = np.array(enA_audio_embeddings)\n",
    "np.save(\"../embeddings/seamless-align-enA-esA_enA_audio_metavoice_embeddings.npy\", arr_enA)\n",
    "print(arr_enA.shape)\n",
    "\n",
    "arr_esA.shape, arr_enA.shape"
   ],
   "id": "ee881f70443a21e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2178, 256)\n",
      "(2178, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2178, 256), (2178, 256))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T22:29:20.091296Z",
     "start_time": "2024-08-27T22:29:16.782982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"andrewsiah/Eval_Pref_Dataset_with_stella_400M_v5_embeddings\")\n",
    "\n",
    "# DatasetDict({\n",
    "#     test: Dataset({\n",
    "#         features: ['person_weight', 'prompt_1', 'response_1_a', 'response_1_b', 'chosen_1', 'prompt_2', 'response_2_a', 'response_2_b', 'chosen_2', 'prompt_3', 'response_3_a', 'response_3_b', 'chosen_3', 'prompt_4', 'response_4_a', 'response_4_b', 'chosen_4', 'prompt_5', 'response_5_a', 'response_5_b', 'chosen_5', 'user_history_length', 'test_prompt', 'best_response', 'best_response_model', 'best_response_reward', 'gpt4o_response', 'gpt4o_reward', 'person_id', 'test_prompt_embedding', 'prompt_response_1_a_embedding', 'prompt_response_1_b_embedding', 'prompt_response_2_a_embedding', 'prompt_response_2_b_embedding', 'prompt_response_3_a_embedding', 'prompt_response_3_b_embedding', 'prompt_response_4_a_embedding', 'prompt_response_4_b_embedding', 'prompt_response_5_a_embedding', 'prompt_response_5_b_embedding', 'user_embedding_avg_winning', 'user_embedding_avg_losing', 'user_embedding_avg_win_minus_lose'],\n",
    "#         num_rows: 1000\n",
    "#     })\n",
    "# })\n",
    "\n",
    "# Save the embeddings to np array and save them separately\n",
    "test_prompt_embeddings = []\n",
    "prompt_response_1_a_embeddings = []\n",
    "prompt_response_1_b_embeddings = []\n",
    "prompt_response_2_a_embeddings = []\n",
    "prompt_response_2_b_embeddings = []\n",
    "prompt_response_3_a_embeddings = []\n",
    "prompt_response_3_b_embeddings = []\n",
    "prompt_response_4_a_embeddings = []\n",
    "prompt_response_4_b_embeddings = []\n",
    "prompt_response_5_a_embeddings = []\n",
    "prompt_response_5_b_embeddings = []\n",
    "for row in ds[\"test\"]:\n",
    "    if row[\"test_prompt_embedding\"] is not None:\n",
    "        test_prompt_embeddings.append(row[\"test_prompt_embedding\"])\n",
    "    if row[\"prompt_response_1_a_embedding\"] is not None:\n",
    "        prompt_response_1_a_embeddings.append(row[\"prompt_response_1_a_embedding\"])\n",
    "    if row[\"prompt_response_1_b_embedding\"] is not None:\n",
    "        prompt_response_1_b_embeddings.append(row[\"prompt_response_1_b_embedding\"])\n",
    "    if row[\"prompt_response_2_a_embedding\"] is not None:\n",
    "        prompt_response_2_a_embeddings.append(row[\"prompt_response_2_a_embedding\"])\n",
    "    if row[\"prompt_response_2_b_embedding\"] is not None:\n",
    "        prompt_response_2_b_embeddings.append(row[\"prompt_response_2_b_embedding\"])\n",
    "    if row[\"prompt_response_3_a_embedding\"] is not None:\n",
    "        prompt_response_3_a_embeddings.append(row[\"prompt_response_3_a_embedding\"])\n",
    "    if row[\"prompt_response_3_b_embedding\"] is not None:\n",
    "        prompt_response_3_b_embeddings.append(row[\"prompt_response_3_b_embedding\"])\n",
    "    if row[\"prompt_response_4_a_embedding\"] is not None:\n",
    "        prompt_response_4_a_embeddings.append(row[\"prompt_response_4_a_embedding\"])\n",
    "    if row[\"prompt_response_4_b_embedding\"] is not None:\n",
    "        prompt_response_4_b_embeddings.append(row[\"prompt_response_4_b_embedding\"])\n",
    "    if row[\"prompt_response_5_a_embedding\"] is not None:\n",
    "        prompt_response_5_a_embeddings.append(row[\"prompt_response_5_a_embedding\"])\n",
    "    if row[\"prompt_response_5_b_embedding\"] is not None:\n",
    "        prompt_response_5_b_embeddings.append(row[\"prompt_response_5_b_embedding\"])\n",
    "\n",
    "test_prompt_arr = np.array(test_prompt_embeddings, dtype=object)\n",
    "prompt_response_1_a_arr = np.array(prompt_response_1_a_embeddings, dtype=object)\n",
    "prompt_response_1_b_arr = np.array(prompt_response_1_b_embeddings, dtype=object)\n",
    "prompt_response_2_a_arr = np.array(prompt_response_2_a_embeddings, dtype=object)\n",
    "prompt_response_2_b_arr = np.array(prompt_response_2_b_embeddings, dtype=object)\n",
    "prompt_response_3_a_arr = np.array(prompt_response_3_a_embeddings, dtype=object)\n",
    "prompt_response_3_b_arr = np.array(prompt_response_3_b_embeddings, dtype=object)\n",
    "prompt_response_4_a_arr = np.array(prompt_response_4_a_embeddings, dtype=object)\n",
    "prompt_response_4_b_arr = np.array(prompt_response_4_b_embeddings, dtype=object)\n",
    "prompt_response_5_a_arr = np.array(prompt_response_5_a_embeddings, dtype=object)\n",
    "prompt_response_5_b_arr = np.array(prompt_response_5_b_embeddings, dtype=object)\n",
    "\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_test_prompt_embeddings.npy\", test_prompt_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_1_a_embeddings.npy\", prompt_response_1_a_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_1_b_embeddings.npy\", prompt_response_1_b_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_2_a_embeddings.npy\", prompt_response_2_a_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_2_b_embeddings.npy\", prompt_response_2_b_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_3_a_embeddings.npy\", prompt_response_3_a_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_3_b_embeddings.npy\", prompt_response_3_b_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_4_a_embeddings.npy\", prompt_response_4_a_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_4_b_embeddings.npy\", prompt_response_4_b_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_5_a_embeddings.npy\", prompt_response_5_a_arr)\n",
    "np.save(\"../embeddings/Eval_Pref_Dataset_with_stella_400M_v5_prompt_response_5_b_embeddings.npy\", prompt_response_5_b_arr)\n",
    "\n",
    "test_prompt_arr.shape, prompt_response_1_a_arr.shape, prompt_response_1_b_arr.shape, prompt_response_2_a_arr.shape, prompt_response_2_b_arr.shape, prompt_response_3_a_arr.shape, prompt_response_3_b_arr.shape, prompt_response_4_a_arr.shape, prompt_response_4_b_arr.shape, prompt_response_5_a_arr.shape, prompt_response_5_b_arr.shape\n",
    "\n"
   ],
   "id": "e6cdedf76b3c86ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1024),\n",
       " (1000, 1024),\n",
       " (1000, 1024),\n",
       " (1000, 1024),\n",
       " (1000, 1024),\n",
       " (1000, 1024),\n",
       " (1000, 1024),\n",
       " (1000, 1024),\n",
       " (1000, 1024),\n",
       " (1000, 1024),\n",
       " (1000, 1024))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T22:31:54.883726Z",
     "start_time": "2024-08-27T22:30:05.671887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Cohere/wikipedia-22-12-simple-embeddings\")\n",
    "\n",
    "# DatasetDict({\n",
    "#     train: Dataset({\n",
    "#         features: ['id', 'title', 'text', 'url', 'wiki_id', 'views', 'paragraph_id', 'langs', 'emb'],\n",
    "#         num_rows: 485859\n",
    "#     })\n",
    "# })\n",
    "\n",
    "# Save the embeddings to np array and save them separately\n",
    "embeddings = []\n",
    "for row in ds[\"train\"]:\n",
    "    if row[\"emb\"] is not None:\n",
    "        embeddings.append(row[\"emb\"])\n",
    "arr = np.array(embeddings,  dtype=object)\n",
    "np.save(\"../embeddings/wikipedia-22-12-simple-embeddings.npy\", arr)\n",
    "arr.shape\n"
   ],
   "id": "b0a347e36b6df470",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485859, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f8ce3b5208b2fae3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
